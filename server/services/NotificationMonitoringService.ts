/**
 * Ø®Ø¯Ù…Ø© Ù…Ø±Ø§Ù‚Ø¨Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
 * ØªØ¯Ø¹Ù… structured logging ÙˆÙ…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
 */

import { db } from "../db";
import { sql } from "drizzle-orm";

export interface NotificationMetric {
  id: string;
  notificationId?: string;
  recipientId: string;
  deliveryMethod: string;
  status: 'pending' | 'sent' | 'failed' | 'skipped';
  sentAt: Date;
  latencyMs: number;
  failureReason?: string;
  retryCount?: number;
  channelUsed: string;
  createdAt: Date;
}

export interface SystemAlert {
  type: 'performance' | 'failure_rate' | 'queue_backup' | 'system_error';
  severity: 'low' | 'medium' | 'high' | 'critical';
  message: string;
  metadata: Record<string, any>;
  timestamp: Date;
}

export interface PerformanceMetrics {
  totalNotifications: number;
  successRate: number;
  averageLatency: number;
  failureRate: number;
  queueSize: number;
  processingTime: number;
  channelBreakdown: Record<string, number>;
  hourlyTrends: Array<{ hour: number; count: number; successRate: number }>;
}

export class NotificationMonitoringService {
  private alertThresholds = {
    successRate: 0.95, // 95%
    maxLatency: 5000, // 5 Ø«ÙˆØ§Ù†ÙŠ
    maxQueueSize: 1000,
    maxFailureRate: 0.05 // 5%
  };

  /**
   * ØªØ³Ø¬ÙŠÙ„ Ø­Ø¯Ø« ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ structured logging
   */
  async logEvent(
    level: 'info' | 'warn' | 'error' | 'debug',
    category: string,
    message: string,
    metadata: Record<string, any> = {},
    requestId?: string,
    userId?: string,
    notificationId?: string
  ): Promise<void> {
    const logEntry = {
      timestamp: new Date().toISOString(),
      level,
      category,
      message,
      requestId: requestId || this.generateRequestId(),
      userId,
      notificationId,
      metadata,
      pid: process.pid,
      service: 'notification-system'
    };

    // ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„ÙƒÙˆÙ†Ø³ÙˆÙ„ Ø¨ØµÙŠØºØ© JSON
    console.log(JSON.stringify(logEntry));

    // Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ù‡Ù…Ø©
    if (level === 'error' || level === 'warn') {
      await this.saveLogToDatabase(logEntry);
    }
  }

  /**
   * Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
   */
  private async saveLogToDatabase(logEntry: any): Promise<void> {
    try {
      await db.execute(sql`
        INSERT INTO error_logs (
          error_level, category, message, metadata, 
          created_at
        ) VALUES (
          ${logEntry.level}, ${logEntry.category}, ${logEntry.message}, 
          ${JSON.stringify(logEntry.metadata)}, 
          ${new Date()}
        )
      `);
    } catch (error) {
      console.error('ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:', error);
    }
  }

  /**
   * Ø¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
   */
  async getPerformanceMetrics(timeRange: 'hour' | 'day' | 'week' = 'day'): Promise<PerformanceMetrics> {
    const hours = timeRange === 'hour' ? 1 : timeRange === 'day' ? 24 : 168;
    const startTime = new Date(Date.now() - hours * 60 * 60 * 1000);

    try {
      // Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
      const generalStats = await db.execute(sql`
        SELECT 
          COUNT(*) as total_notifications,
          COUNT(CASE WHEN status = 'sent' THEN 1 END) as successful,
          COUNT(CASE WHEN status = 'failed' THEN 1 END) as failed,
          AVG(latency_ms) as avg_latency,
          MAX(latency_ms) as max_latency
        FROM notification_metrics 
        WHERE created_at >= ${startTime}
      `);

      // Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù‚Ù†ÙˆØ§Øª
      const channelStats = await db.execute(sql`
        SELECT 
          channel_used,
          COUNT(*) as count,
          COUNT(CASE WHEN status = 'sent' THEN 1 END) as successful
        FROM notification_metrics 
        WHERE created_at >= ${startTime}
        GROUP BY channel_used
      `);

      // Ø­Ø¬Ù… Ø§Ù„Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ø­Ø§Ù„ÙŠ
      const queueStats = await db.execute(sql`
        SELECT 
          COUNT(*) as queue_size,
          COUNT(CASE WHEN status = 'pending' THEN 1 END) as pending,
          COUNT(CASE WHEN status = 'processing' THEN 1 END) as processing
        FROM notification_queue
      `);

      // Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø¨Ø§Ù„Ø³Ø§Ø¹Ø©
      const hourlyTrends = await db.execute(sql`
        SELECT 
          EXTRACT(HOUR FROM created_at) as hour,
          COUNT(*) as count,
          COUNT(CASE WHEN status = 'sent' THEN 1 END) as successful
        FROM notification_metrics 
        WHERE created_at >= ${startTime}
        GROUP BY EXTRACT(HOUR FROM created_at)
        ORDER BY hour
      `);

      const generalRow = generalStats.rows[0];
      const queueRow = queueStats.rows[0];

      const totalNotifications = Number(generalRow.total_notifications) || 0;
      const successfulNotifications = Number(generalRow.successful) || 0;
      const failedNotifications = Number(generalRow.failed) || 0;

      const successRate = totalNotifications > 0 ? successfulNotifications / totalNotifications : 1;
      const failureRate = totalNotifications > 0 ? failedNotifications / totalNotifications : 0;

      // ØªØ¬Ù…ÙŠØ¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù‚Ù†ÙˆØ§Øª
      const channelBreakdown: Record<string, number> = {};
      channelStats.rows.forEach(row => {
        channelBreakdown[row.channel_used as string] = Number(row.count);
      });

      // ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø¨Ø§Ù„Ø³Ø§Ø¹Ø©
      const trends = hourlyTrends.rows.map(row => ({
        hour: Number(row.hour),
        count: Number(row.count),
        successRate: Number(row.count) > 0 ? Number(row.successful) / Number(row.count) : 0
      }));

      return {
        totalNotifications,
        successRate,
        averageLatency: Number(generalRow.avg_latency) || 0,
        failureRate,
        queueSize: Number(queueRow.queue_size) || 0,
        processingTime: Number(generalRow.max_latency) || 0,
        channelBreakdown,
        hourlyTrends: trends
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      await this.logEvent('error', 'monitoring', 'ÙØ´Ù„ ÙÙŠ Ø¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡', { error: errorMessage });
      throw error;
    }
  }

  /**
   * ÙØ­Øµ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª
   */
  async checkAlerts(): Promise<SystemAlert[]> {
    const alerts: SystemAlert[] = [];
    
    try {
      const metrics = await this.getPerformanceMetrics('hour');

      // ÙØ­Øµ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­
      if (metrics.successRate < this.alertThresholds.successRate) {
        alerts.push({
          type: 'failure_rate',
          severity: metrics.successRate < 0.85 ? 'critical' : 'high',
          message: `Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ù…Ù†Ø®ÙØ¶: ${(metrics.successRate * 100).toFixed(2)}%`,
          metadata: { 
            currentRate: metrics.successRate, 
            threshold: this.alertThresholds.successRate,
            totalNotifications: metrics.totalNotifications
          },
          timestamp: new Date()
        });
      }

      // ÙØ­Øµ Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
      if (metrics.averageLatency > this.alertThresholds.maxLatency) {
        alerts.push({
          type: 'performance',
          severity: metrics.averageLatency > 10000 ? 'critical' : 'medium',
          message: `Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø±ØªÙØ¹: ${metrics.averageLatency.toFixed(0)}ms`,
          metadata: { 
            currentLatency: metrics.averageLatency, 
            threshold: this.alertThresholds.maxLatency 
          },
          timestamp: new Date()
        });
      }

      // ÙØ­Øµ Ø­Ø¬Ù… Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
      if (metrics.queueSize > this.alertThresholds.maxQueueSize) {
        alerts.push({
          type: 'queue_backup',
          severity: metrics.queueSize > 2000 ? 'critical' : 'high',
          message: `Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ù…Ø²Ø¯Ø­Ù…: ${metrics.queueSize} Ø¹Ù†ØµØ±`,
          metadata: { 
            currentSize: metrics.queueSize, 
            threshold: this.alertThresholds.maxQueueSize 
          },
          timestamp: new Date()
        });
      }

      // ÙØ­Øµ Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙØ´Ù„
      if (metrics.failureRate > this.alertThresholds.maxFailureRate) {
        alerts.push({
          type: 'failure_rate',
          severity: metrics.failureRate > 0.15 ? 'critical' : 'medium',
          message: `Ù…Ø¹Ø¯Ù„ ÙØ´Ù„ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ù…Ø±ØªÙØ¹: ${(metrics.failureRate * 100).toFixed(2)}%`,
          metadata: { 
            currentRate: metrics.failureRate, 
            threshold: this.alertThresholds.maxFailureRate 
          },
          timestamp: new Date()
        });
      }

      // ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
      for (const alert of alerts) {
        await this.logEvent(
          alert.severity === 'critical' ? 'error' : 'warn',
          'system_alert',
          alert.message,
          alert.metadata
        );
      }

      return alerts;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      await this.logEvent('error', 'monitoring', 'ÙØ´Ù„ ÙÙŠ ÙØ­Øµ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª', { error: errorMessage });
      return [{
        type: 'system_error',
        severity: 'critical',
        message: 'ÙØ´Ù„ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©',
        metadata: { error: errorMessage },
        timestamp: new Date()
      }];
    }
  }

  /**
   * ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚ÙŠØ§Ø³ Ø¬Ø¯ÙŠØ¯
   */
  async recordMetric(metric: Omit<NotificationMetric, 'id' | 'createdAt'>): Promise<void> {
    try {
      await db.execute(sql`
        INSERT INTO notification_metrics (
          notification_id, recipient_id, delivery_method, status, 
          sent_at, latency_ms, failure_reason, retry_count, channel_used
        ) VALUES (
          ${metric.notificationId || null}, ${metric.recipientId}, 
          ${metric.deliveryMethod}, ${metric.status}, ${metric.sentAt}, 
          ${metric.latencyMs}, ${metric.failureReason || null}, 
          ${metric.retryCount || 0}, ${metric.channelUsed}
        )
      `);

      await this.logEvent(
        'info', 
        'metric_recorded', 
        'ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚ÙŠØ§Ø³ Ø¬Ø¯ÙŠØ¯',
        { 
          status: metric.status, 
          channel: metric.channelUsed, 
          latency: metric.latencyMs 
        },
        undefined,
        metric.recipientId,
        metric.notificationId
      );

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      await this.logEvent(
        'error', 
        'metric_recording', 
        'ÙØ´Ù„ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³', 
        { error: errorMessage, metric }
      );
      throw error;
    }
  }

  /**
   * ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
   */
  async cleanupOldData(retentionDays: number = 30): Promise<void> {
    const cutoffDate = new Date(Date.now() - retentionDays * 24 * 60 * 60 * 1000);
    
    try {
      // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
      const metricsResult = await db.execute(sql`
        DELETE FROM notification_metrics 
        WHERE created_at < ${cutoffDate}
      `);

      // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
      const logsResult = await db.execute(sql`
        DELETE FROM error_logs 
        WHERE created_at < ${cutoffDate}
      `);

      await this.logEvent(
        'info', 
        'cleanup', 
        'ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©',
        { 
          retentionDays,
          deletedMetrics: metricsResult.rowCount || 0,
          deletedLogs: logsResult.rowCount || 0
        }
      );

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      await this.logEvent(
        'error', 
        'cleanup', 
        'ÙØ´Ù„ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©', 
        { error: errorMessage }
      );
      throw error;
    }
  }

  /**
   * ØªÙ‚Ø±ÙŠØ± Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
   */
  async getSystemHealth(): Promise<{
    status: 'healthy' | 'warning' | 'critical';
    metrics: PerformanceMetrics;
    alerts: SystemAlert[];
    recommendations: string[];
  }> {
    try {
      const metrics = await this.getPerformanceMetrics('hour');
      const alerts = await this.checkAlerts();
      
      // ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
      let status: 'healthy' | 'warning' | 'critical' = 'healthy';
      if (alerts.some(a => a.severity === 'critical')) {
        status = 'critical';
      } else if (alerts.some(a => a.severity === 'high' || a.severity === 'medium')) {
        status = 'warning';
      }

      // ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†
      const recommendations: string[] = [];
      
      if (metrics.successRate < 0.95) {
        recommendations.push('ÙØ­Øµ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ ÙˆØªØ­Ø³ÙŠÙ† Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©');
      }
      
      if (metrics.averageLatency > 3000) {
        recommendations.push('ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª');
      }
      
      if (metrics.queueSize > 500) {
        recommendations.push('Ø²ÙŠØ§Ø¯Ø© Ø³Ø±Ø¹Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ø§Ø¨ÙˆØ± Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ù…ØªÙˆØ§Ø²ÙŠØ©');
      }

      if (metrics.failureRate > 0.03) {
        recommendations.push('ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ÙØ´Ù„ ÙˆØªØ­Ø³ÙŠÙ† Ø¢Ù„ÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©');
      }

      return {
        status,
        metrics,
        alerts,
        recommendations
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      await this.logEvent('error', 'health_check', 'ÙØ´Ù„ ÙÙŠ ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…', { error: errorMessage });
      
      return {
        status: 'critical',
        metrics: {} as PerformanceMetrics,
        alerts: [{
          type: 'system_error',
          severity: 'critical',
          message: 'ÙØ´Ù„ ÙÙŠ ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…',
          metadata: { error: errorMessage },
          timestamp: new Date()
        }],
        recommendations: ['Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©', 'ÙØ­Øµ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª']
      };
    }
  }

  /**
   * ØªØ´ØºÙŠÙ„ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¯ÙˆØ±ÙŠØ©
   */
  startPeriodicMonitoring(intervalMinutes: number = 5): void {
    setInterval(async () => {
      try {
        const health = await this.getSystemHealth();
        
        if (health.status !== 'healthy') {
          await this.logEvent(
            health.status === 'critical' ? 'error' : 'warn',
            'periodic_check',
            `Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: ${health.status}`,
            { 
              alertsCount: health.alerts.length,
              recommendations: health.recommendations 
            }
          );
        }

        // ØªÙ†Ø¸ÙŠÙ Ø¯ÙˆØ±ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙŠÙˆÙ…ÙŠÙ‹Ø§)
        const now = new Date();
        if (now.getHours() === 2 && now.getMinutes() === 0) {
          await this.cleanupOldData();
        }

      } catch (error) {
        console.error('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ©:', error);
      }
    }, intervalMinutes * 60 * 1000);

    console.log(`ğŸ” ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ© ÙƒÙ„ ${intervalMinutes} Ø¯Ù‚Ø§Ø¦Ù‚`);
  }

  /**
   * Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù Ø·Ù„Ø¨ ÙØ±ÙŠØ¯
   */
  private generateRequestId(): string {
    return `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  /**
   * ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ Ù„Ù„Ø£Ø¯Ø§Ø¡
   */
  async generatePerformanceReport(timeRange: 'day' | 'week' | 'month' = 'day'): Promise<{
    period: string;
    summary: PerformanceMetrics;
    trends: any[];
    topFailures: any[];
    channelPerformance: any[];
  }> {
    const hours = timeRange === 'day' ? 24 : timeRange === 'week' ? 168 : 720;
    const startTime = new Date(Date.now() - hours * 60 * 60 * 1000);

    try {
      const metricRange = timeRange === 'month' ? 'week' : timeRange;
      const summary = await this.getPerformanceMetrics(metricRange);

      // Ø£ÙƒØ«Ø± Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ÙØ´Ù„ Ø´ÙŠÙˆØ¹Ø§Ù‹
      const topFailures = await db.execute(sql`
        SELECT 
          failure_reason, 
          COUNT(*) as count,
          COUNT(DISTINCT recipient_id) as affected_users
        FROM notification_metrics 
        WHERE created_at >= ${startTime} 
        AND status = 'failed' 
        AND failure_reason IS NOT NULL
        GROUP BY failure_reason 
        ORDER BY count DESC 
        LIMIT 10
      `);

      // Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
      const channelPerformance = await db.execute(sql`
        SELECT 
          channel_used,
          COUNT(*) as total,
          COUNT(CASE WHEN status = 'sent' THEN 1 END) as successful,
          AVG(latency_ms) as avg_latency,
          MIN(latency_ms) as min_latency,
          MAX(latency_ms) as max_latency
        FROM notification_metrics 
        WHERE created_at >= ${startTime}
        GROUP BY channel_used
        ORDER BY total DESC
      `);

      return {
        period: timeRange,
        summary,
        trends: summary.hourlyTrends,
        topFailures: topFailures.rows.map(row => ({
          reason: row.failure_reason,
          count: Number(row.count),
          affectedUsers: Number(row.affected_users)
        })),
        channelPerformance: channelPerformance.rows.map(row => ({
          channel: row.channel_used,
          total: Number(row.total),
          successful: Number(row.successful),
          successRate: Number(row.total) > 0 ? Number(row.successful) / Number(row.total) : 0,
          avgLatency: Number(row.avg_latency) || 0,
          minLatency: Number(row.min_latency) || 0,
          maxLatency: Number(row.max_latency) || 0
        }))
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      await this.logEvent('error', 'report_generation', 'ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡', { error: errorMessage });
      throw error;
    }
  }
}

// Ø¥Ù†Ø´Ø§Ø¡ instance Ø¹Ø§Ù… Ù„Ù„Ø®Ø¯Ù…Ø©
export const notificationMonitoringService = new NotificationMonitoringService();